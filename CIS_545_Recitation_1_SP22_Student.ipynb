{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIS_545_Recitation_1_SP22_Student.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MIngjianZhang/editor/blob/master/CIS_545_Recitation_1_SP22_Student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPjLRzG_nmMs"
      },
      "source": [
        "# CIS 545 Recitation 1: Intro to Python and Pandas\n",
        "> 1/14 @ 1:45 PM https://upenn.zoom.us/j/99266553438, Ang Li and Carol Li\n",
        "\n",
        "**Recitation Overview:**\n",
        "1. Colab Tips\n",
        "2. Python basics: Syntax, For Loops, List Comprehension\n",
        "3. Pandas basics: Series & DataFrames, Apply & Merge Operations, Groupby\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX4N4Zut-PD8"
      },
      "source": [
        "# üí° Colab Tips"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h28MCRUtIlEJ"
      },
      "source": [
        "### Integration with Drive\n",
        "\n",
        "Colaboratory is integrated with Google Drive. It allows you to share, comment, and collaborate on the same document with multiple people:\n",
        "\n",
        "* The **SHARE** button (top-right of the toolbar) allows you to share the notebook and control permissions set on it just like Google docs, slides, sheets, etc. This will be useful for the term/final project.\n",
        "\n",
        "* **File ‚Üí Make a Copy** creates a copy of the notebook in Drive. Do it for homeworks always! Make sure the file name becomes `Copy_of_{...}.ipynb`\n",
        "> This is very important for starting homeworks!\n",
        "\n",
        "* **File ‚Üí Save** saves the File to Drive. **File->Save and checkpoint** pins the version so it doesn't get deleted from the revision history. \n",
        "\n",
        "* **File ‚Üí Revision history** shows the notebook's revision history. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bln_jQsEL6S_"
      },
      "source": [
        "### Working with Python in Colab\n",
        "Colaboratory is built on top of [Jupyter Notebook](https://jupyter.org/). Below are some examples of convenience functions provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPnbXlwyMEBO"
      },
      "source": [
        "Long running python processes can be interrupted:\n",
        "`Runtime ‚Üí Restart runtime ‚Üí You should see a green  tick at the top right`\n",
        "* Generally useful for when the dataset stops loading (eg. local copy already exists) or when your code runs forever.\n",
        "* Sometimes Jupyter/Colab memory gets really weird...and just needs to be reset\n",
        "* Make sure to reinitialize PennGrader after you do this (and run any cells that create intermediate df's because you won't have them anymore!) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TURB3BnRMDAw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7cb9fc-4f22-430d-86f0-0218aa920dc1"
      },
      "source": [
        "import time\n",
        "print(\"Sleeping\")\n",
        "time.sleep(30) # sleep for a while; interrupt me!\n",
        "print(\"Done Sleeping\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sleeping\n",
            "Done Sleeping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO2knJBOKJR6"
      },
      "source": [
        "### PennGrader\n",
        "```\n",
        "%%capture\n",
        "!pip3 install penngrader\n",
        "from penngrader.grader import *\n",
        "```\n",
        "```\n",
        "# PLEASE ENSURE YOUR PENN-ID IS ENTERED CORRECTLY. IF NOT, THE AUTOGRADER WON'T KNOW WHO` \n",
        "# TO ASSIGN POINTS TO YOU IN OUR BACKEND \n",
        "STUDENT_ID = 19104444 # YOUR PENN-ID GOES HERE AS AN INTEGER #\n",
        "```\n",
        "```\n",
        "grader = PennGrader(homework_id = 'CIS545_Fall_2020_HW1', student_id = STUDENT_ID)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnPhlvcFNgyR"
      },
      "source": [
        "### Tab-Completion and Exploring Code\n",
        "\n",
        "Colab provides tab completion to explore attributes of Python objects, as well as to quickly view documentation strings. As an example, first run the following cell to import the  [`numpy`](http://www.numpy.org) module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwpv59iBNmlc"
      },
      "source": [
        "import numpy as np "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7btJPOmYNoc9"
      },
      "source": [
        "If you now insert your cursor after ``np.random.`` and press **Tab**, you will see the list of available completions within the ``np.random`` submodule."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKZYualxNrGf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "a62ca6ff-7a04-44d6-f7df-c8e1b752b64d"
      },
      "source": [
        "np.random."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-09b63e346a93>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    np.random.\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKmN9HEkNtFk"
      },
      "source": [
        "If you type an open parenthesis followed by the **Tab** key after any function or class in the module, you will see a pop-up of its documentation string:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f19VlK4iNwOi"
      },
      "source": [
        "np.random.rand()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNNnrIZ7NyeH"
      },
      "source": [
        "To open the documentation in a persistent pane at the bottom of your screen, add a **?** after the object or method name and execute the cell using **Shift+Enter**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnQLM47DN1qg"
      },
      "source": [
        "np.random?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-l4o8IJJIjw"
      },
      "source": [
        "### Exceptions\n",
        "\n",
        "Exceptions are formatted nicely in Colab outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3Pc7pHcJMhm"
      },
      "source": [
        "x = 1\n",
        "y = 4\n",
        "z = y/(1-x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-OW8g4AKXEI"
      },
      "source": [
        "### Rich, Interactive Outputs\n",
        "Until now all of the generated outputs have been text, but they can be more interesting, like the chart below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZBndwtbKgA2"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "ys = 200 + np.random.randn(100)\n",
        "x = [x for x in range(len(ys))]\n",
        "\n",
        "plt.plot(x, ys, '-')\n",
        "plt.fill_between(x, ys, 195, where=(ys > 195), facecolor='g', alpha=0.6)\n",
        "\n",
        "plt.title(\"Fills and Alpha Example\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I25zmZsHJ9M2"
      },
      "source": [
        "### Submission\n",
        "`Files ‚Üí Download .ipynb ‚Üí Submit through Gradescope` \\\n",
        "**!! DO NOT run autograder cells after the deadline !!** -- your work will be marked as late if you do this!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCrOLTnhD3qv"
      },
      "source": [
        "# üêç Python\n",
        "Python is a programming language that is very popular among the data science, machine learning community.\n",
        "It is a higher-level programming language than Java, and has an extensive collection of libraries that can be easily installed.\n",
        "**We require that you use python for this class, so it is important to be familiar with it.**\n",
        "\n",
        "### Python vs Java\n",
        "- Java is compiled, but Python is not: you directly run the Python file\n",
        "- Java is statically typed (the types of the variables cannot change), and you do not declare types in Python\n",
        "```\n",
        "# This works in python\n",
        "x = 3\n",
        "x = \"python\"\n",
        "```\n",
        "- Python does not use curly braces like Java. Instead, it uses whitespace (tabs/spaces) to infer the scope of methods, for loops, etc.\n",
        "```\n",
        "for i in range(10):\n",
        "      print(i * 2)      # Indent by 4 spaces\n",
        "      print(i * 4)\n",
        "      for j in range(4):\n",
        "          print(i * j)  # Indent 8 spaces\n",
        "print('Done')       # No indent, runs after for loop\n",
        "```\n",
        "- Boolean values are now `True` and `False`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYYcZ2H7OuiL"
      },
      "source": [
        "### String Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB_cL2TAnjju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47049b41-bc76-40ee-a3f2-cf04c5755c44"
      },
      "source": [
        "s = \"ABCdef\"\n",
        "s = 'ABCdef'\n",
        "\n",
        "# Length\n",
        "print(len(s))  # 6\n",
        "\n",
        "# Standard Indexing: Notice hard brackets and 0-indexing\n",
        "print(s[0])      # 'A'\n",
        "print(s[1])      # 'B'\n",
        "print(s[5])      # 'f'\n",
        "# print(s[100])  # Error\n",
        "\n",
        "# Range Indexing\n",
        "print(s[1:4])    # 'BCd'\n",
        "print(s[2:])     # 'Cdef'\n",
        "print(s[:2])     # 'AB'\n",
        "print(s[1:100])  # 'BCdef'\n",
        "\n",
        "# Negative Indexing\n",
        "print(s[-1])    # 'f'\n",
        "print(s[-2])    # 'e'\n",
        "print(s[:-1])   # 'ABCde'\n",
        "print(s[:-3])   # 'ABC'\n",
        "print(s[::-1])  # 'fedCBA'\n",
        "\n",
        "# Concatenation\n",
        "print(s + 'xyz')     # 'ABCdefxyz'\n",
        "# print(s + 123)     # Error\n",
        "print(s + str(123))  # 'ABCdef123'\n",
        "\n",
        "# Splitting\n",
        "print(s.split('C'))  # ['AB', 'def']\n",
        "print(\"  hi  \".strip())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "A\n",
            "B\n",
            "f\n",
            "BCd\n",
            "Cdef\n",
            "AB\n",
            "BCdef\n",
            "f\n",
            "e\n",
            "ABCde\n",
            "ABC\n",
            "fedCBA\n",
            "ABCdefxyz\n",
            "ABCdef123\n",
            "['AB', 'def']\n",
            "hi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duS1SUd0O8dv"
      },
      "source": [
        "## If Statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HQFSWS4O7zk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "625a4ac3-efec-4cd5-e5d2-80b2ed805c61"
      },
      "source": [
        "# Python doesn't require parentheses\n",
        "a, b = 7, 10\n",
        "\n",
        "# equality\n",
        "if a == 7:\n",
        "    print('yes')\n",
        "else:\n",
        "    print('no')\n",
        "    \n",
        "# not equal\n",
        "if a != 8:\n",
        "    print('neq')\n",
        "    \n",
        "# and &&\n",
        "if a > 5 and b <= 10:\n",
        "    print('1')\n",
        "elif a > 10:\n",
        "    print('2')\n",
        "else:\n",
        "    print('3')\n",
        "\n",
        "# or\n",
        "if a < 10 or b > 100:\n",
        "    print('yes')\n",
        "    \n",
        "# Strings also use '=='\n",
        "s = 'abc'\n",
        "if s == 'abc':\n",
        "    print('here')\n",
        "    \n",
        "    \n",
        "t = 'cabcd'\n",
        "if s in t:\n",
        "    print(\"hi\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yes\n",
            "neq\n",
            "1\n",
            "yes\n",
            "here\n",
            "hi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJwKGHGSPCo_"
      },
      "source": [
        "## For Loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rNKSr0-PCJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "466c8ccd-710b-4073-d740-b17d62d3546e"
      },
      "source": [
        "a = [0, 8, 3, 5, 1]\n",
        "\n",
        "range(5)     # Dynamically generates 0, 1, 2, 3, 4\n",
        "range(1, 5)  # 1, 2, 3, 4\n",
        "\n",
        "# \"Standard\" for loop from Java\n",
        "for i in range(len(a)):\n",
        "    print(a[i])\n",
        "\n",
        "# Iterate over each element in the list\n",
        "for x in a:\n",
        "    print(x)\n",
        "    \n",
        "# Iterating through dictionaries\n",
        "d = {0: 'a', 1: 'b', 2: 'c'}\n",
        "for key, value in d.items():\n",
        "    print(str(key) + ' -> ' + value)\n",
        "    \n",
        "    \n",
        "# Loop over items in an array and get the index at the same time\n",
        "for index, item in enumerate(a):\n",
        "  print(index, item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "8\n",
            "3\n",
            "5\n",
            "1\n",
            "0\n",
            "8\n",
            "3\n",
            "5\n",
            "1\n",
            "0 -> a\n",
            "1 -> b\n",
            "2 -> c\n",
            "0 0\n",
            "1 8\n",
            "2 3\n",
            "3 5\n",
            "4 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEhEWrthOxv4"
      },
      "source": [
        "## Lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf1aPEkKO3zc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf093dd8-20dc-4af7-adab-72cfa4cbabb0"
      },
      "source": [
        "a = [0, 4, 2, 8, 9]  # Create a list with initial items\n",
        "b = []  # Create an empty list\n",
        "\n",
        "# Length\n",
        "print(len(a))  # 5\n",
        "\n",
        "# The same indexing operations on strings work for lists\n",
        "print(a[1])    # 4\n",
        "print(a[2:4])  # [2, 8]\n",
        "print(a[-2])   # 8\n",
        "\n",
        "# Sort the list\n",
        "print(sorted(a))                # [0, 2, 4, 8, 9] Creates a copy, does not modify the original list\n",
        "print(sorted(a, reverse=True))  # [9, 8, 4, 2, 0] Also a copy\n",
        "\n",
        "# Add items to the end of the list\n",
        "a.append(10)  # Returns nothing\n",
        "print(a)      # [0, 4, 2, 8, 9, 10] \n",
        "a += [1, 12]  # Returns nothing\n",
        "print(a)      # [0, 4, 2, 8, 9, 10, 1, 12]\n",
        "\n",
        "# Lists don't have to be the same type in python\n",
        "a.append('machine learning')\n",
        "print(a)            # [0, 4, 2, 8, 9, 10, 1, 12, 'machine learning']\n",
        "# print(sorted(a))  # Causes an error\n",
        "\n",
        "# Searching\n",
        "print(8 in a)    # True\n",
        "print(100 in a)  # False\n",
        "print(a.index(8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "4\n",
            "[2, 8]\n",
            "8\n",
            "[0, 2, 4, 8, 9]\n",
            "[9, 8, 4, 2, 0]\n",
            "[0, 4, 2, 8, 9, 10]\n",
            "[0, 4, 2, 8, 9, 10, 1, 12]\n",
            "[0, 4, 2, 8, 9, 10, 1, 12, 'machine learning']\n",
            "True\n",
            "False\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VRh6tinPOb-"
      },
      "source": [
        "## List Comprehension\n",
        "A cool and extremely useful feature of Python! Good for condensing code using loops and conditionals. \n",
        "\n",
        "The general syntax is:\n",
        "\n",
        "```\n",
        "[ <expression> for <name> in <list> if <filter> ]\n",
        "```\n",
        "\n",
        "List comprehension also applies to dictionaries and sets, as follows.\n",
        "\n",
        "```\n",
        "{ <expression> for <key>, <value> in <dict> if <filter> }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGec0WJRPSCi"
      },
      "source": [
        "# Sometimes code can be simplified using list/dictionary comprehensions\n",
        "def add_one(x):\n",
        "  return x + 1\n",
        "\n",
        "# The standard way to apply a function to every element and save in y\n",
        "x = [0, 1, 2, 3]\n",
        "y = []\n",
        "for i in range(len(x)):\n",
        "  y.append(add_one(x[i]))\n",
        "\n",
        "# This is equivalent to the above\n",
        "y = [add_one(x_i) for x_i in x]\n",
        "# funtion to element for element in data structure\n",
        "\n",
        "# Add conditionals\n",
        "y2 = [add_one(x_i) for x_i in x if x_i > 1]\n",
        "# function to element for element in data structure if element meets conditional\n",
        "\n",
        "# Dictionary comprehensions can be used to create dictionaries easily.\n",
        "# This creates a mapping from x_i -> x_i * 4\n",
        "d = {x_i : x_i * 4 for x_i in x}\n",
        "# element key : function to element value for element in data structure\n",
        "print(d)\n",
        "print(d[2])  # 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPjuKHthZqrn"
      },
      "source": [
        "### TODO #1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_Ur2MzeZ8ym"
      },
      "source": [
        "# this is Carol's credit card spendings for August\n",
        "\n",
        "daily_spendings = [[0, 30, 35, 31, 15, 60, 82], \n",
        "                   [22, 3, 40, 19, 1020, 55, 36], \n",
        "                   [578, 21, 965, 9, 680, 60, 82], \n",
        "                   [0, 75000, 5, 99, 13, 101, 8]]\n",
        "\n",
        "# Though late, she realizes that her identity has been stolen! \n",
        "# Get a list of all the exorbitant daily spendings (defined to be > 100): i.e. [1020, 578, 965, 680, 75000, 101]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-ta0-QjfAZ_"
      },
      "source": [
        "##### EXERCISE #####\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmtoKTB2Hcng"
      },
      "source": [
        "# Pandas üêº \n",
        "\n",
        "Documentation is your best friend: https://pandas.pydata.org/docs/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcEJTO4kHnfR"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMVJQx-hHwsk"
      },
      "source": [
        "## Series and DataFrames\n",
        "\n",
        "* **Series:** one-dimensional array with hashable axis labels. Parameter is an iterable array-like object, such as lists, dicts, etc.\n",
        "* **DataFrame:** two-dimensional, size-mutable tabular data, consisting of columns of Series. Parameter is an array-like object or DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZsTboy7Hxih"
      },
      "source": [
        "sports = pd.Series(['football', 'basketball',' volleyball','tennis'])\n",
        "\n",
        "population = pd.Series({'Germany': 81.3, 'Belgium': 11.3, 'France': 64.3, \n",
        "                        'United Kingdom': 64.9, 'Netherlands': 16.9})\n",
        "\n",
        "countries = pd.DataFrame({'country': ['Belgium', 'France', 'Germany', 'Netherlands', 'United Kingdom'],\n",
        "        'population': [11.3, 64.3, 81.3, 16.9, 64.9],\n",
        "        'area': [30510, 671308, 357050, 41526, 244820],\n",
        "        'capital': ['Brussels', 'Paris', 'Berlin', 'Amsterdam', 'London']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3YBMxz8H0Hc"
      },
      "source": [
        "sports"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmgEAdNNJwsE"
      },
      "source": [
        "type(sports)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4nHPCDBH2wr"
      },
      "source": [
        "population"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnunKRnXJtAJ"
      },
      "source": [
        "type(population)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVogvzK-KAmD"
      },
      "source": [
        "population.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "836UhQ1dKCLb"
      },
      "source": [
        "population.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm7O9SVjKD9k"
      },
      "source": [
        "population / 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38kCCJabKZfu"
      },
      "source": [
        "To access dataframe variables, use the `.` operator or brackets `[ ]`, or access multiple columns with `[[ ]]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlX-HeHsJ0yn"
      },
      "source": [
        "population['Netherlands'] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOSTN2bBH5Fx"
      },
      "source": [
        "countries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mScC0NJaJqQ8"
      },
      "source": [
        "type(countries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmmgSLGnKxsn"
      },
      "source": [
        "type(countries.area)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKkTGUVLK9sJ"
      },
      "source": [
        "countries['area']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro3269Xuhblv"
      },
      "source": [
        "### TODO #2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U95ELGrhV5K"
      },
      "source": [
        "# What's the difference if we use the double braces, i.e.: \n",
        "# Explore and see! :)\n",
        "\n",
        "##### EXERCISE #####\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNcEZ5VKLyH7"
      },
      "source": [
        "We can also access dataframes using conditional operators, such as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U7I2rJiXoV-"
      },
      "source": [
        "countries.capital == 'London'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A88u8qxLLy4E"
      },
      "source": [
        "# Extract data for UK/London\n",
        "countries[countries.capital == 'London']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueIpWmGBL2IE"
      },
      "source": [
        "# We can also do this without the .\n",
        "countries[countries['capital'] == 'London']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dis7CY7zhqNF"
      },
      "source": [
        "### TODO #3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OWCfx42L4bP"
      },
      "source": [
        "# Now use inequalities: get all countries with area > 100k!\n",
        "\n",
        "##### EXERCISE #####\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s068sUuI4C7"
      },
      "source": [
        "## Creating New Variables\n",
        "Adding columns to the DataFrame!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kbi6CVkI3be"
      },
      "source": [
        "# basic assignment\n",
        "countries['newVar'] = [1,2,3,4,5]\n",
        "countries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRxngu5nH8FX"
      },
      "source": [
        "# using existing columns for assignment\n",
        "# here, we are creating a COMPOSITE VARIABLE defined as:\n",
        "# \"2 * population + sqrt(area)\" for each row in countries\n",
        "countries['newVar'] = countries.population * 2  + countries.area**0.5\n",
        "countries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxlztxbcMCbT"
      },
      "source": [
        "## Apply\n",
        "\n",
        "Apply is a very powerful method which can be used for making major data manipulation tasks. Much faster than standard for loops because of internal optimizations. \n",
        "\n",
        "NOTE: In some assignments, your code could never finish running if you use for loops due to the size of the datasets!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ty8hdeQMB48"
      },
      "source": [
        "%%timeit\n",
        "\n",
        "countries = pd.DataFrame({'country': ['Belgium', 'France', 'Germany', 'Netherlands', 'United Kingdom'],\n",
        "        'population': [11.3, 64.3, 81.3, 16.9, 64.9],\n",
        "        'area': [30510, 671308, 357050, 41526, 244820],\n",
        "        'capital': ['Brussels', 'Paris', 'Berlin', 'Amsterdam', 'London']})\n",
        "\n",
        "for index, row in countries.iterrows():\n",
        "  row['capital'].upper()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55p5XFqXMJn7"
      },
      "source": [
        " %%timeit\n",
        "\n",
        "countries = pd.DataFrame({'country': ['Belgium', 'France', 'Germany', 'Netherlands', 'United Kingdom'],\n",
        "        'population': [11.3, 64.3, 81.3, 16.9, 64.9],\n",
        "        'area': [30510, 671308, 357050, 41526, 244820],\n",
        "        'capital': ['Brussels', 'Paris', 'Berlin', 'Amsterdam', 'London']})\n",
        "\n",
        "countries['capital'] = countries['capital'].apply(lambda x : x.upper())\n",
        "countries\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRB8SapcMMlx"
      },
      "source": [
        "def ageBucket(x):\n",
        "    if x<18:\n",
        "        return \"A. <18\"\n",
        "    elif x<25:\n",
        "        return \"B. 18-25\"\n",
        "    elif x<45:\n",
        "        return \"C. 25-45\"\n",
        "    else:\n",
        "        return \"D. >45\"\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7t1uRLCMO9g"
      },
      "source": [
        "df = pd.DataFrame({'Age': [1, 2, 19, 39, 50]})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J2bUw9kMRlT"
      },
      "source": [
        "Apply can be used on a single column (ie on a Series object)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXBPUkKTiA_9"
      },
      "source": [
        "### TODO #4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etViTX6Ph-Mj"
      },
      "source": [
        "# Let's call ageBucket on every element in Age, and set that as a new column!\n",
        "\n",
        "##### EXERCISE #####\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPUhR_GdMX8y"
      },
      "source": [
        "Apply can also be used on an entire dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcwSyYeOMb_j"
      },
      "source": [
        "df['AgeBucket2'] = df.apply(lambda x : ageBucket(x['Age']),axis=1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trLNk_6DMeQm"
      },
      "source": [
        "Other derivative methods that you can look into are `map` and `applymap`.\n",
        "* `map` works only on Series but has the same functionality as `apply`.\n",
        "* `applymap` works only on dfs and applies to every element excluding the target column. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MpfQ6VJMg82"
      },
      "source": [
        "## Merge Operations\n",
        "\n",
        "Merging with Pandas works pretty much the same as SQL. **There are four merge methods:**\n",
        "1. Left\n",
        "2. Right\n",
        "3. Inner \n",
        "4. Outer\n",
        "\n",
        "This is further demonstrated by the venn diagram below.\n",
        "\n",
        "![join-venn-diagram](https://i.stack.imgur.com/UI25E.jpg)\n",
        "\n",
        "**Basic Syntax:**\n",
        "\n",
        "`pd.merge(left_dataframe, right_dataframe, left_on=\"some_column\", right_on=\"some_column\", how=\"left|right|inner|outer\")`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wprVsAP_PiqR"
      },
      "source": [
        "population = pd.DataFrame({'country': ['Germany', 'Belgium', 'France', \n",
        "                        'United Kingdom', 'United States'],'population': [81.3, 11.3, 64.3, 64.9, 65.9]})\n",
        "\n",
        "countries = pd.DataFrame({'country2': ['Belgium', 'France', 'Germany', 'Netherlands', 'United Kingdom'],\n",
        "        'population': [11.3, 64.3, 81.3, 16.9, 64.9],\n",
        "        'area': [30510, 671308, 357050, 1526, 244820],\n",
        "        'capital': ['Brussels', 'Paris', 'Berlin', 'Amsterdam', 'London']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqM_GY6fPt7j"
      },
      "source": [
        "population"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLtFCFSnPu_e"
      },
      "source": [
        "countries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ichyP_CZPw92"
      },
      "source": [
        "In a Left Merge we are mostly concerned with data on the LEFT side but we would like to add data from \n",
        "the RIGHT side if it has some of the same countries in this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wr0xqi1Pwkg"
      },
      "source": [
        "pd.merge(left=population, right=countries, left_on=\"country\", right_on=\"country2\", how=\"left\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQFxhyB3P4iz"
      },
      "source": [
        "In a Right Merge we are mostly concerned with data on the RIGHT side but we would like to add data from \n",
        "the LEFT side if it has some of the same countries in this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIvaAMy7P6fP"
      },
      "source": [
        "pd.merge(left=population, right=countries, left_on=\"country\", right_on=\"country2\", how=\"right\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ySqeo4bP9VM"
      },
      "source": [
        "With an Inner Merge, we chop up both dataframes and only glue the stuff that matches. If a country isn't in both \n",
        "dataframes, we don't keep it and we don't add NaN's. If no type of join is mentioned, then inner join is the \n",
        "default join. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCvPKiMGP_SQ"
      },
      "source": [
        "# not inner merge\n",
        "pd.merge(left=population, right=countries, left_on=\"country\", right_on=\"country2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOoqGLuQQCVG"
      },
      "source": [
        "# inner merge -- notice how it only contains rows of countries that both DataFrames have\n",
        "pd.merge(left=population, right=countries, left_on=\"country\", right_on=\"country2\", how=\"inner\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRYAmc-vQGYv"
      },
      "source": [
        "With an Outer Merge, we chop up both dataframes and keep everything from both sides. Then we toss in NaN's to fill\n",
        "any blanks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_4ohA-xQHLv"
      },
      "source": [
        "# outer merge -- countries that the DataFrames don't both have are filled with NaN values\n",
        "pd.merge(left=population, right=countries, left_on=\"country\", right_on=\"country2\", how=\"outer\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS3NpPCVQPRE"
      },
      "source": [
        "## Groupby\n",
        "\n",
        "How do we aggregate data and do computations in Python?\n",
        "\n",
        "```\n",
        "dataframe.groupby(<parameters to group>).<aggregate function>\n",
        "```\n",
        "\n",
        "The intermediate format is a \"groupby\" that we can call aggregate functions on and re-transform into a dataframe, for example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDUMNZh7QP-i"
      },
      "source": [
        "pop_countries = pd.merge(left=population[['country']], right=countries, left_on=\"country\", right_on=\"country2\", how=\"outer\")\n",
        "pop_countries['continent'] = pop_countries['country'].apply(lambda x: 'America' if x == 'United States' else 'Europe')\n",
        "pop_countries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75h2jHIUfp6y"
      },
      "source": [
        "pop_countries.groupby('continent').count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VFGpvYHQSYu"
      },
      "source": [
        "# What if we wanted to find the average population?\n",
        "pop_countries.groupby('continent').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEOpNttqiMBB"
      },
      "source": [
        "### TODO #5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2b8fyOWiPgD"
      },
      "source": [
        "# How about only for area for Europe, in a dataframe format? \n",
        "\n",
        "##### EXERCISE #####\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVF4XCYEQcjf"
      },
      "source": [
        "There's a lot of other formatting things that we can examine, such as how to transform things from a `groupby` form, the aggregated dataframe, or a standard dataframe with a numerical index. Take a look at the `reset_index` function [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html) -- do you think we should have `drop = True` or `drop = False` here?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L_2TKJNigfA"
      },
      "source": [
        "### TODO #6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x53rJTIiib_A"
      },
      "source": [
        "# Now how do we get the contents back to a column?\n",
        "\n",
        "##### EXERCISE #####\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qZ4FFRjQgcj"
      },
      "source": [
        "## Missing Data\n",
        "How to handle missing data (`NaN`'s)? Most common commands used are `fillna` and `dropna`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7-M2fttQfBd"
      },
      "source": [
        "missing_df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f', 'h'],columns=['one', 'two', 'three'])\n",
        "missing_df['four'] = 'bar'\n",
        "missing_df['five'] = missing_df['one'] > 0\n",
        "missing_df.loc[['a','c','h'],['one','four']] = np.nan\n",
        "missing_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiqufrL8i-On"
      },
      "source": [
        "### TODO #7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTebX2fgjCH0"
      },
      "source": [
        "# fillna replaces NA/NaN values with the given value in the command.\n",
        "# replace all the values in missing_df with 0!\n",
        "# see here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html\n",
        "\n",
        "##### EXERCISE #####\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z_mKpdcQmeU"
      },
      "source": [
        "missing_df['one'] = missing_df['one'].fillna('missing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzEoTziJQnun"
      },
      "source": [
        "missing_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyYeAj8mQp0Z"
      },
      "source": [
        "`dropna` is used to drop the rows or columns with NA/NaN values.\n",
        "\n",
        "**`dropna` Usage:**\n",
        "* `axis` argument determines if rows or columns which contain missing values are removed.\n",
        "* `axis = 0`: Drop rows which contain missing values.\n",
        "* `axis = 1`: Drop columns which contain missing value.\n",
        "* `how` argument determines if row or column is removed from DataFrame, when we have at least one NA or all NA.\n",
        "* `how = any`: If any NA values are present, drop that row or column. (default)\n",
        "* `how = all` : If all values are NA, drop that row or column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHFgNjihjVwD"
      },
      "source": [
        "### TODO #8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDAtZxPxjTjd"
      },
      "source": [
        "# now drop all the rows that have missing values\n",
        "\n",
        "##### EXERCISE ##### \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHLykHSLQtao"
      },
      "source": [
        "temp_df = missing_df.dropna(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FMSjx5oQueh"
      },
      "source": [
        "temp_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FdTpt9xQveK"
      },
      "source": [
        "missing_df['six'] = [1, 2, 3, 4, 5]\n",
        "missing_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Extip8rUQwte"
      },
      "source": [
        "missing_df.dropna(axis=1, how = 'all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlIcmJDOjoex"
      },
      "source": [
        "### TODO #9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO7I3UdMjmY-"
      },
      "source": [
        "# dropping rows only for cases when columns 'two' or 'four' have nulls\n",
        "\n",
        "##### EXERCISE ##### \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQNUmctejtIU"
      },
      "source": [
        "### TODO #10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWvTmbbDjxvT"
      },
      "source": [
        "# what happens if we call the above for column 'two' and 'five'?\n",
        "\n",
        "##### EXERCISE ##### \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGk8DYZ3Q0vM"
      },
      "source": [
        "We attribute our work to https://developers.google.com/edu/ as well as previous TA's Andrew Cui, Carol Li and Celine Lee. "
      ]
    }
  ]
}